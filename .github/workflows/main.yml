name: Run Ollama with Localtunnel on Linux

on:
  workflow_dispatch:

jobs:
  run-ollama:
    runs-on: ubuntu-latest
    steps:
      - name: Install Ollama on Linux
        shell: bash
        run: |
          curl -fsSL https://ollama.com/install.sh | sh

      - name: Start Ollama server
        shell: bash
        run: |
          ollama serve &
          sleep 10  # Wait for server to start

      - name: Get Local IP (optional for logs)
        shell: bash
        run: |
          LOCAL_IP=$(hostname -I | awk '{print $1}')
          echo "LOCAL_IP=$LOCAL_IP" >> $GITHUB_ENV
          echo "Ollama is running locally at $LOCAL_IP:11434"

      - name: Install Node.js (required for Localtunnel)
        uses: actions/setup-node@v3
        with:
          node-version: '16'

      - name: Install Localtunnel
        shell: bash
        run: |
          npm install -g localtunnel
          curl https://loca.lt/mytunnelpassword

      - name: Start Localtunnel
        shell: bash
        run: |
          lt --local-host localhost --port 11434 > tunnel_url.txt 2>&1 &
          sleep 5  # Wait for tunnel to establish

      - name: Display Localtunnel URL
        shell: bash
        run: |
          TUNNEL_URL=$(cat tunnel_url.txt | grep -o 'https://[^ ]*.loca.lt')
          echo "TUNNEL_URL=$TUNNEL_URL" >> $GITHUB_ENV
          echo "Ollama is accessible at $TUNNEL_URL"

      - name: Keep workflow running for 5 hours
        shell: bash
        run: |
          sleep 18000
